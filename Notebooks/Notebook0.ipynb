{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with MDCS via Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Set the path to MDCS core files (i.e. MDCS.py, etc.) so that the required imports can work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from MDCS import NBAccess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create an instance of MDCS.NBAccess class to interface with MDCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nb = NBAccess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nb.init(prj_folder, session=True) takes in 2 args, prj_folder to store the output  if any and the boolean session value to create a unique session based subfolder within the prj_folder. This helps to further isolate the output to facilitate multiple test scenarios. If the prj_folder is omitted however, the default location is the folder named 'output' located one level up from where the MDCS core files are located. e.g. nb.init('c:/path/to/data/output'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add_job using a unique user defined job_id followed by the standard MDCS args flags assigned with the user values. Any additional custom args can be passed naming the arg prefixed with '__', for e.g. __custom_value = \"custom\". The use of any custom args if any would depend on the logic the custom functions assigned by (c = ?) have on them. Please note, the implementation of the custom functions are in the MDCS_UC source file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.add_job('workflow1', c = 'hello1', p = [\"7$pixelvalue\"], __custom_value = \"custom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the following job named 'workflow2',  the custom arg __pixelval gets its value assigned using the pixelvalue that was an input to the previous workflow identified by its unique job_id 'workflow1'. Similarly, the custom arg __hello1 gets its value from the output of the function named 'hello1' in the same job. The addressing syntax to fetch values from the previous worflows is '@job_id/i|o/flag/cmd|arg name'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.add_job('workflow2', c = 'hello2', __pixelval = \"@workflow1/i/p/pixelvalue\", __hello1=\"@workflow1/o/hello1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.add_job('workflow3', c = 'hello3+hello_cnt', __hello2 = \"@workflow2/o/hello2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing nb.add_job multiple times with the same job_id will not add any additional jobs, instead the values of the last args used will replace the existing values for the same job_id if found. For e.g. the value for the c = ? can be adjusted to test only a section of the workflow for debugging purpose starting off initially with just c = 'hello1' and adding the following commands one at a time until the whole w/f is tested. Caveat, if any changes to the MDCS core is done, it's possibe the Notebook may not reflect those changes until the Notebook gets restarted, this means testing/manipulating of c = ? args can only be done once all the changes have been completed in the core files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all the jobs, each job can be thought as a separate workflow. In this case, the 'workfows' jobs jobs are all identified by their unique job_ids and will run in the order they've been added into MDCS using the function add_job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for the status of the command 'hello1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.get_status('workflow1', 'hello1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the output for the command 'hello1' for the job_id 'workflow1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.get_output('workflow2', 'hello2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for the collective results of the job_id (workflow3) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.get_status('workflow3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
